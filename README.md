&nbsp;<div align="center">
<img src="https://github.com/riyajath-ahamed/musync/blob/master/src/Asset/logo1.png" alt="image" height="80px">
</div>

# Musync - Music Streaming Application with Emotion recognition and Playlist generation using Image Processing - FE
Music Streaming system is designed to enhance the user's listening experience by analyzing their emotions through facial expressions and creating a customized playlist to match their mood. The system utilizes a camera to capture the user's facial expressions and an Image Processing algorithm to analyze those expressions to determine the user's current emotional state. 

Built with React, Tailwind CSS, and TensorFlow, Musync provides a personalized music experience by analyzing user emotions from images and generating suitable playlists.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [License](#license)
- [Model Accuracy](#model-accuracy)

## Features

- **Emotion Recognition**: Detects user emotions from images using TensorFlow.
- **Playlist Generation**: Creates personalized playlists based on detected emotions.
- **Music Streaming**: Stream high-quality music with an extensive library of songs.
- **User-Friendly Interface**: Intuitive and responsive design using React and Tailwind CSS.

## Technologies Used

- **React**: Frontend library for building user interfaces.
- **Tailwind CSS**: Utility-first CSS framework for styling.
- **TensorFlow**: Machine learning framework for emotion recognition.

## Model Accuracy
<img src="https://github.com/riyajath-ahamed/musync/assets/64283797/6021dbe2-601d-438d-8eea-3a709d7d0094" alt="image" width="500px">


## License
This project is licensed under the MIT License. See the [LICENSE]() file for details.
